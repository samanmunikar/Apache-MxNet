{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "from mxnet import gluon, nd\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mx.random.seed(42)\n",
    "x = mx.random.uniform(shape=(10,3))\n",
    "y = mx.random.uniform(shape=(10,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once we have our data in ndArray. We can use gluon.data.dataset.ArrayDataset to create the gluon dataset\n",
    "dataset = gluon.data.dataset.ArrayDataset(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\n",
       " [0.74707687 0.37641123 0.46362457]\n",
       " <NDArray 3 @cpu(0)>,\n",
       " \n",
       " [0.35440788]\n",
       " <NDArray 1 @cpu(0)>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = dataset[4]\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = gluon.data.vision.datasets.MNIST(train=True)\n",
    "test_dataset = gluon.data.vision.datasets.MNIST(train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "sample_image = train_dataset[19][0]\n",
    "print(sample_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1aa7259e710>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "imshow(sample_image[:,:,0].asnumpy(), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImageFolder Datasets\n",
    "# image_datasets = gluon.data.vision.datasets.ImageFolderDataset('path_to_folder')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCustomDataset(gluon.data.Dataset):\n",
    "    def __init__(self, dict_data):\n",
    "        self.dict_data = dict_data\n",
    "        self.dict_keys = list(dict_data.keys())\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.dict_data[self.dict_keys[idx]]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dict_data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MyCustomDataset({\n",
    "    'a':mx.nd.array(1,),\n",
    "    'b':mx.nd.array(2,),\n",
    "    'c':mx.nd.array(3,)\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "3.0\n",
       "<NDArray  @cpu(0)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gluon Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_fn(data, label):\n",
    "    data = data.astype('float32') / 225\n",
    "    return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = gluon.data.vision.datasets.MNIST(train=True).transform(transform_fn)\n",
    "test_dataset = gluon.data.vision.datasets.MNIST(train=False).transform(transform_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[1.1333333]\n",
       "<NDArray 1 @cpu(0)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_image = train_dataset[19][0]\n",
    "nd.max(sample_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vision Transforms\n",
    "gluon.data.vision.transforms has implemented transformation function that are common in computer vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet import gluon, nd\n",
    "from mxnet.gluon.data.vision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ToTensor Transformation\n",
    "Convert an image NDArray of shape(H,W,C) in range[0,255] to a goat tensor NDArray of shape(C,H,W) in the range[0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = gluon.data.vision.datasets.MNIST(train=True)\n",
    "train_dataset[19][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 28, 28)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_tensor = transforms.ToTensor()\n",
    "train_dataset = train_dataset.transform_first(to_tensor)  # apply transform to image not label\n",
    "train_dataset[19][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if apply transformation to both image and label then use .transform method\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize\n",
    "Normalize a tensor of ahspe (C,H,W) with mean and standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, std = (0.1307,),(0.3081,)\n",
    "normalize = transforms.Normalize(mean, std)\n",
    "train_dataset = train_dataset.transform_first(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compose\n",
    "Sequentially compose multiple transformation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_fn = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean,std)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = gluon.data.vision.datasets.MNIST(train=True).transform(transform_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation via Transformation\n",
    "Reduce Overfitting\n",
    "\n",
    "* transforms.Resize\n",
    "* transforms.CenterCrop\n",
    "* transforms.RandomSizedCrop\n",
    "* transforms.RandomFlipLeftRight\n",
    "* transfomrs.RandomBrightness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gluon DataLoaders\n",
    "mini-batch of data from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "mx.random.seed(42)\n",
    "X = mx.random.uniform(shape=(10,3))\n",
    "y = mx.random.uniform(shape=(10,1))\n",
    "dataset = gluon.data.dataset.ArrayDataset(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_batch has shape (5, 3) and y_batch has shape (5, 1)\n",
      "X_batch has shape (5, 3) and y_batch has shape (5, 1)\n"
     ]
    }
   ],
   "source": [
    "data_loader = gluon.data.DataLoader(dataset, batch_size=5, last_batch='keep')\n",
    "for X_batch, y_batch in data_loader:\n",
    "    print(\"X_batch has shape {} and y_batch has shape {}\".format(X_batch.shape, y_batch.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parallel Data Loading\n",
    "from multiprocessing import cpu_count\n",
    "CPU_COUNT = cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_batch has shape (5, 3) and y_batch has shape (5, 1)\n",
      "X_batch has shape (5, 3) and y_batch has shape (5, 1)\n"
     ]
    }
   ],
   "source": [
    "data_loader = gluon.data.DataLoader(dataset, batch_size=5, num_workers=CPU_COUNT)\n",
    "for X_batch, y_batch in data_loader:\n",
    "    print(\"X_batch has shape {} and y_batch has shape {}\".format(X_batch.shape, y_batch.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet.gluon.data.vision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = gluon.data.vision.datasets.MNIST(train=True)\n",
    "test_dataset = gluon.data.vision.datasets.MNIST(train=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.RandomFlipTopBottom(),\n",
    "    transforms.RandomFlipLeftRight()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataloader = gluon.data.DataLoader(train_dataset.transform_first(transform), batch_size=5, shuffle=True)\n",
    "for X_batch, y_batch in train_dataloader:\n",
    "    imshow(X_batch[3,:,:,0].asnumpy(), cmap='gray')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
